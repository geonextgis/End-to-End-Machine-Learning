{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2598c68d-09e8-4c56-b862-ed34b0dce0cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Stochastic Gradient Descent**\n",
    "Stochastic Gradient Descent (SGD) with a single-row update, also known as online SGD, is a variant of the traditional SGD algorithm where instead of using mini-batches of data for each parameter update, you update the model's parameters one data point (or row) at a time. In other words, after processing each individual data point, the model's parameters are updated based on the gradient computed for that single data point. This approach is sometimes referred to as \"online learning.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c70bda9-fed7-41e8-8698-3005cf318dee",
   "metadata": {},
   "source": [
    "<center><img src=\"https://editor.analyticsvidhya.com/uploads/58182variations_comparison.png\" style=\"width: 60%\"></ceneter>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6890869-e1c0-4bdc-8e86-f90f07c11452",
   "metadata": {},
   "source": [
    "Here's how SGD with a single-row update works:\n",
    "\n",
    "1. **Initialization**: Start with an initial set of model parameters.\n",
    "\n",
    "2. **Data Shuffling**: The training dataset is often shuffled to ensure that the order of data points does not bias the training process.\n",
    "\n",
    "3. **Iterative Updates**: For each training iteration (or epoch), the algorithm processes one data point from the training set. The model's parameters are updated based on the gradient of the loss function with respect to that single data point.\n",
    "\n",
    "4. **Gradient Computation**: The gradient of the loss function with respect to the model parameters is computed by backpropagating errors through the network (for neural networks) or using analytical derivatives (for simpler models). The gradient represents how the loss changes with small perturbations in the model parameters for that specific data point.\n",
    "\n",
    "5. **Parameter Update**: The model parameters are adjusted in the opposite direction of the gradient, just like in traditional SGD. The learning rate controls the step size during each update.\n",
    "\n",
    "6. **Repeat**: Steps 3-5 are repeated for the entire training dataset or until convergence criteria are met.\n",
    "\n",
    "Online SGD can have some advantages and disadvantages:\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "1. **Efficiency**: Online SGD can be very efficient, as it processes one data point at a time, making it suitable for streaming data or scenarios with limited memory.\n",
    "\n",
    "2. **Quick Convergence**: Online SGD can converge quickly, especially when the data is abundant and diverse.\n",
    "\n",
    "3. **Adaptability**: It can adapt to changing data distributions and non-stationary data, making it useful in online learning and real-time applications.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "1. **High Variability**: Since updates are based on individual data points, the parameter updates can be highly variable and noisy, which may result in a less stable convergence.\n",
    "\n",
    "2. **Slower Convergence**: Online SGD can converge slower than traditional SGD with mini-batches due to the high variance in parameter updates.\n",
    "\n",
    "3. **Difficulty in Hyperparameter Tuning**: Choosing an appropriate learning rate and other hyperparameters can be more challenging because of the high variance in updates.\n",
    "\n",
    "Online SGD is typically used in situations where computational resources or memory are limited, or when the data distribution is constantly changing. It's commonly employed in online learning scenarios, such as recommendation systems, where new data arrives continuously and must be processed as it comes in. However, it may require careful tuning and monitoring to achieve optimal convergence and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603de32f-ce86-44f7-9e62-22c9697921a5",
   "metadata": {},
   "source": [
    "## **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbd3a43e-c78f-452d-9b16-63969fce28f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7d2a80-5c2d-4970-955c-0fc809ba4780",
   "metadata": {},
   "source": [
    "## **Load a Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea65644-2b8a-406b-af6b-c2ada02342c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a38ebf4-28df-46fa-b2a4-9ea8069b81a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read the Diabetes data\n",
    "X, y = load_diabetes(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78583173-c3be-44bc-b308-76b59f265516",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(442, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb5918-5aa9-42fd-9068-cbdc8e0c0c79",
   "metadata": {},
   "source": [
    "## **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e02354-3193-4360-b9e8-30977f7a4bc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e376eaaf-1508-4c8a-8d33-8719f6fe2ded",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c7008-2cdf-47f9-b668-2a53b8f8246d",
   "metadata": {},
   "source": [
    "## **Apply Linear Regression with Ordinary Least Squares (OLS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cb9670-0991-493b-9214-f089d50b15fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d8a9d18-0460-4b42-a789-ff03eb019ebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time taken is: 0.017316102981567383\n"
     ]
    }
   ],
   "source": [
    "# Store the initial time in a variable\n",
    "start = time.time()\n",
    "\n",
    "# Instantiate a linear regression object\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Print the actual time taken to fit the data\n",
    "print(\"The Time taken is:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef59492-651e-42a2-b957-1540115b48b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " [ -52.46478548 -193.50733393  579.49108514  272.453666   -504.64830389\n",
      "  241.62372969  -69.76596029   86.61313961  721.92083806   26.78067442] \n",
      "\n",
      "Intercept: 153.71901624380382\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\\n\", lr.coef_, \"\\n\")\n",
    "print(\"Intercept:\", lr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8992447-7054-42ef-9ebe-c66fade0905e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the test data\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23ed1a1-0533-4942-ac66-0eda94c2deb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the R2 Score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c09b90fe-fa06-4e8e-87fe-05da79903c03",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.39289927216962917\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cc9b3a-b766-404e-9ccc-596f9b395eed",
   "metadata": {},
   "source": [
    "## **Apply Multiple Linear Regression with Stochastic Gradient Descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5e45983-a23b-4871-8944-594b0e8ba651",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a class to apply gradient descent\n",
    "class SGDRegressor:\n",
    "    def __init__(self, lr=0.01, epochs=100):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.coef_ = None\n",
    "        self.intercept_ = None\n",
    "        \n",
    "    def fit(self, X_train, y_train):\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                idx = np.random.randint(0, X_train.shape[0])\n",
    "                \n",
    "                # Predict the y_hat\n",
    "                y_hat = np.dot(X_train[idx], self.coef_) + self.intercept_\n",
    "                \n",
    "                # Update the intercept using a single row\n",
    "                intercept_der = -2 * (y_train[idx] - y_hat)\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_der)\n",
    "                \n",
    "                # Update the coefficients using a single row\n",
    "                coef_der = -2 * np.dot((y_train[idx] - y_hat), X_train[idx])\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_der)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.coef_) + self.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7069d5a-0eaf-4e4a-9536-f01fcb4a2eb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Time taken is: 0.34311676025390625\n"
     ]
    }
   ],
   "source": [
    "# Store the initial time in a variable\n",
    "start = time.time()\n",
    "\n",
    "# Instantiate a SGDRegressor object\n",
    "sgdr = SGDRegressor(lr=0.03, epochs=100)\n",
    "\n",
    "# Fit the data\n",
    "sgdr.fit(X_train, y_train)\n",
    "\n",
    "# Print the actual time taken to fit the data\n",
    "print(\"The Time taken is:\", time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bef5ac1-2628-46c6-bda9-365fd150a430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      " [ -41.03889143 -194.92599674  590.11828356  272.37981486  -69.86465318\n",
      " -152.76619768 -238.47971595   88.93869043  513.01930642   56.26845156] \n",
      "\n",
      "Intercept: 155.20404866654545\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept\n",
    "print(\"Coefficients:\\n\", sgdr.coef_, \"\\n\")\n",
    "print(\"Intercept:\", sgdr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5648f8c5-766c-415f-9660-93bc0a9c7067",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the test data\n",
    "y_pred = sgdr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6663fb4-bd75-4c7f-b4d8-59cb117de776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.38663888603937424\n"
     ]
    }
   ],
   "source": [
    "# Calculate the R2 Score\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fba185-53ba-45de-b670-5b8eee38058e",
   "metadata": {},
   "source": [
    "## **Stochastic Gradient Descent with Scikit-Learn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66e63b66-62e6-4994-a1c5-420441761eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94289840-a180-47c6-910a-b202940576d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor(learning_rate=&#x27;constant&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor(learning_rate=&#x27;constant&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor(learning_rate='constant')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a SGDRegressor object\n",
    "reg = SGDRegressor(loss='squared_error', learning_rate='constant', eta0=0.01)\n",
    "\n",
    "# Fit the data\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ddab2f1-6f6d-4813-9b87-52d43bee0b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict the test data\n",
    "y_pred = reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b0d687b-086b-4f0c-9189-2ad95f403a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.39411766076013666\n"
     ]
    }
   ],
   "source": [
    "# Calculate the R2 Score\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
